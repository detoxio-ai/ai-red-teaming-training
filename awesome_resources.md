# **Awesome List of Resources**

## **1. Basics**
- **Vectors**: [3Blue1Brown - Vectors](https://www.3blue1brown.com/lessons/vectors)
- **Neural Networks**: [3Blue1Brown - Neural Networks](https://www.3blue1brown.com/lessons/neural-networks)

## **2. Large Language Models (LLMs)**
### **Visualizations**
- **Tokenization (OpenAI)**: [OpenAI Tokenizer](https://platform.openai.com/tokenizer)
- **Embedding Projector**: [TensorFlow Projector](https://projector.tensorflow.org/)
- **LLM Inferencing Visualization**: [Transformer Explainer](https://poloclub.github.io/transformer-explainer/)
- **LLM Architecture (3D)**: [LLM 3D Visualization](https://bbycroft.net/llm)
- **LLMs as a Story**: [Financial Times Generative AI](https://ig.ft.com/generative-ai/)
- **Visual LLM Introduction**: [3Blue1Brown Mini-LLM](https://www.3blue1brown.com/lessons/mini-llm)
- **LLM Architecture**: [3Blue1Brown GPT](https://www.3blue1brown.com/lessons/gpt)
- **Self Attention**: [3Blue1Brown Attention](https://www.3blue1brown.com/lessons/attention)
- **LLM Quantization**: [Quantization Guide](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)

### **Comparisons**
- **LLM Comparison**: [Artificial Analysis AI](https://artificialanalysis.ai/)

### **Advanced Topics**
- **Mamba Architecture**: [Mamba Guide](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state)

## **3. AI Red Teaming Skills**
### **Adversarial Prompt Engineering**
- **Introduction to Prompt Engineering**: [Learn Prompting](https://learnprompting.org/docs/basics/prompt_engineering)

### **Running Models Locally**
- **Ollama**: [Download Ollama](https://ollama.com/download)
- **Ollama GitHub**: [Ollama Repository](https://github.com/ollama/ollama)

### **Adversarial Tools**
- **Garak**: [Garak GitHub](https://github.com/NVIDIA/garak)
- **Pyrit**
- **dspy**: [GitHub dspy-redteam](https://github.com/haizelabs/dspy-redteam)
- **Textattack**: [GitHub TextAttack](https://github.com/QData/TextAttack)
- **TextAttack Recipes**: [TextAttack Documentation](https://textattack.readthedocs.io/en/latest/3recipes/attack_recipes_cmd.html)

## **4. Security Frameworks**
- **NIST RMF Framework (Latest Version)**
- **AI Risk Management Framework (2nd Draft)**
- **Gen AI Security & Privacy Risks**
- **2023 MAD (Machine Learning, AI & Data) Landscape**
- **CISA Roadmap for Artificial Intelligence**
- **Gradient Flow: AI 2023 Trends**
- **Cloud of LLM Testing Approaches and Techniques**
- **Forrester Securing Generative AI**
- **Mitre Atlas**
- **OWASP Top 10 for LLMs**

## **5. Notebooks**
- **Tools Setup**: [Kaggle Notebook](https://www.kaggle.com/code/jchauhan/lrt-lab-tools-installation-and-walkthrough)
- **Tokenization**: [Kaggle Notebook](https://www.kaggle.com/code/jchauhan/tokenization-llm-red-teaming-basics)
- **Embeddings**: [Kaggle Notebook](https://www.kaggle.com/code/jchauhan/embeddings-llm-red-teaming)
- **Garak - LLM Red Teaming**: [Kaggle Notebook](https://www.kaggle.com/code/jchauhan/lrt-ai-red-teaming-garak-tool/)

## **6. Research Papers**
- **Generative AI Misuse Taxonomy**: [ArXiv Paper](https://arxiv.org/pdf/2406.13843)
- **Threat Modeling Generative AI**: [AWS Blog](https://aws.amazon.com/blogs/security/threat-modeling-your-generative-ai-workload-to-evaluate-security-risk/)
- **Generative AI Security Matrix**: [AWS Blog](https://aws.amazon.com/blogs/security/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix/)
- **Prompt Injections**: [EMNLP 2023](https://aclanthology.org/2023.emnlp-main.302.pdf)


## Agents 

### Agents Framework 

AutoGPT
https://github.com/Significant-Gravitas/AutoGPT


### Agents Risks

https://github.com/precize/OWASP-Agentic-AI


## Research Papers

### LLM Models

[**Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data**](https://arxiv.org/pdf/2406.13843v2)
[**Adversarial Misuse of Generative AI**](https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai)
[**Google/SAIF Map**](https://saif.google/secure-ai-framework/saif-map)
[**Disrupting malicious uses of our models: an update February 2025**](https://cdn.openai.com/threat-intelligence-reports/disrupting-malicious-uses-of-our-models-february-2025-update.pdf)


### AI in Security
[**Awesome-LLM4Cybersecurity**](https://github.com/tmylla/Awesome-LLM4Cybersecurity)