# ðŸš€ Local Installation (Python + pip)

This guide explains how to install **dtx** in your local Python environment.  
Recommended if you plan to:
- âœ… Develop locally
- âœ… Run models like Tiny-LLM, GPT-2, or Hugging Face directly in your environment
- âœ… Avoid external tools like Docker

---

## âœ… Prerequisites

- **Python** `>= 3.8`
- **pip** (Python package manager)
- **Git** (optional, if you plan to clone templates manually)

Check your Python and pip version:

```bash
python --version
pip --version
```

---

## âœ… Step 1: Install dtx

### ðŸ‘‰ If you already have PyTorch installed

Install only `dtx`:

```bash
pip install dtx
```

> âœ… Use this if you have an existing PyTorch setup.

---

### ðŸ‘‰ If you do **not** have PyTorch installed (Recommended)

Install `dtx` with the `[pytorch]` extras to include everything you need for local model execution:

```bash
pip install dtx[pytorch]
```

This installs:
- âœ… `torch` â€” Core deep learning library
- âœ… `transformers` â€” Hugging Face models

> **Recommended** if you plan to run models locally without cloud APIs.

---

## âœ… Step 2: Verify Installation

Check if `dtx` is installed and accessible:

```bash
dtx --help
```

You should see the list of available commands.

If you see an error, check your `PATH` or virtual environment setup.

---

## âœ… Optional: Create a Virtual Environment (Best Practice)

To isolate your dependencies, itâ€™s best to use a virtual environment.

### Linux/macOS:

```bash
python -m venv .venv
source .venv/bin/activate
pip install dtx[pytorch]
```

### Windows:

```bash
python -m venv .venv
.venv\Scripts\activate
pip install dtx[pytorch]
```

> ðŸ§© Tip: This avoids dependency conflicts with other Python projects.

---

## âœ… Summary

| Scenario | Command |
|----------|----------|
| Existing PyTorch installation | `pip install dtx` |
| No PyTorch installed (recommended) | `pip install dtx[pytorch]` |
| Verify installation | `dtx --help` |

---

## âœ… Next Steps

- âœ… Check available datasets:  
  ```bash
  dtx datasets list
  ```

- âœ… Test a local LLM:  
  ```bash
  dtx redteam run hf_model --url arnir0/Tiny-LLM --dataset beaver --eval ibm38
  ```

- âœ… Try dummy agent test (no model needed):  
  ```bash
  dtx redteam run echo --dataset beaver --eval ibm38
  ```

