# **Introduction to AI Red Teaming**

This section of the repository provides an overview of AI Red Teaming, covering its history, risks, and the taxonomy of attacks. It is designed to equip readers with a foundational understanding of AI risks and adversarial techniques.

---

## **Structure**

The following topics are covered in this section:

### **1.1 History of AI Risks**
- Learn about the historical evolution of AI risks, challenges, and failures in AI systems.
- File: [1_1_history_of_ai_risks.md](1_1_history_of_ai_risks.md)

### **1.2 AI Risks**
- Explore the various types of risks AI systems pose, including technical, ethical, and societal concerns.
- File: [1_2_ai_risks.md](1_2_ai_risks.md)

### **1.3 What is AI Red Teaming?**
- Understand the definition and purpose of AI Red Teaming as a security and evaluation practice.
- File: [1_3_ai_red_teaming.md](1_3_ai_red_teaming.md)

### **1.4 AI Attacks Taxonomy (Part 1)**
- Learn about the different types of AI attacks and their classification in this first part of the taxonomy.
- File: [1_4_ai_attacks_taxonomy_part1.md](1_4_ai_attacks_taxonomy_part1.md)

### **1.5 AI Attacks Taxonomy (Part 2)**
- Continue exploring the AI attacks taxonomy with advanced techniques and case studies in the second part.
- File: [1_5_ai_attacks_taxonomy_part2.md](1_5_ai_attacks_taxonomy_part2.md)

### **1.6 Jailbreaking Demo**
- A practical demonstration of jailbreaking techniques and their implications for AI system security.
- File: [1_6_jailbreaking_demo.md](1_6_jailbreaking_demo.md)

---

